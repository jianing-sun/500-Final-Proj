\documentclass [12pt,letterpaper]{exam}
\usepackage{amsmath, amsthm, amsfonts, amssymb, amscd, latexsym}
\usepackage{type1cm}
\usepackage{simplemath}

\oddsidemargin  0.0in 
\evensidemargin 0.0in 
\textwidth      6.0in
\headheight     0.0in 
\topmargin      1.0in 
\textheight     8.5in

\header{ECSE-500-01-1}{Assignment 9}{4.11.2005}

\newcounter{count}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\begin{questions}

\question For n=1,2,3,... , and for $x$ real, put 
$$
f_n(x)=\frac{x}{1+nx^2}
$$ 
Show that $\{ f_n \}$ converges uniformly (on $\Real$) to a function $f$. What is this limit function $f$ ?\\

Proof: For fixed $x \in \mathbb{R}, f_n(x) \rightarrow 0$ as n $\rightarrow \infty$. To show uniform convergence, qwe need to show $\sup_{x \in \mathbb{R}} |f_n(x)| \rightarrow 0$ as $n \rightarrow \infty$. We see $\lim_{|x| \rightarrow \infty} |f_n(x)| = 0$. As $f_n$ is differentiable everywhere, then:\\
$$f_{n}^{'}(x) = \frac{1-nx^2}{(1+nx^2)^2}$$
We can find that $f_{n}^{'}(x)$ is 0 at $x = \pm \frac{1}{\sqrt{n}}$. We substitute $x = \pm \frac{1}{\sqrt{n}}$ into $f_n(x)$, then:
$$f_n(\frac{1}{\sqrt{n}}) = \frac{\frac{1}{\sqrt{n}}}{1 + n(\frac{1}{\sqrt{n}})^2} = \frac{1}{2\sqrt{n}}$$
$$f_n(\frac{-1}{\sqrt{n}}) = -\frac{1}{2\sqrt{n}}$$
Therefore, as $n \rightarrow \infty$, $\sup_{x \in \mathbb{R}} |f_n(x)| = \frac{1}{2\sqrt{n}} \rightarrow 0$\\
Hence $\big\{ f_n \big\}$ convenges uniformly to a function $f$ on $\mathbb{R}$. The limit of function $f$ is $\frac{1}{2\sqrt{n}}$.\\

\question %Young 1.1 (p11)
Let $a<b$ in $\Real$. Show that the space $W[a,b]$ of continuously differentiable functions on $[a,b]$
with values in $\Real$, is an inner product space with respect to pointwise addition $\bigl( (f+g)(t)=f(t)+g(t)\bigr)$ and
scalar multiplication $\bigl( (\alpha f)(t)=\alpha f(t)\bigr)$, and inner product
$$
\langle f,g\rangle = \int_{a}^{b} f(t)g(t)+f'(x)g'(x) dt
$$
Proof: For any $f,g \in W[a,b]$ and $\alpha \in \mathbb{R}$, $f+g$ and $\alpha f$ are both continuously differentiable, so W[a,b] is closed under addition and scalar multiplication. \\
If $f,g \in W[a,b]$, then $f$ and $g$ are continuously differentiable, and hence $f{g}$ and $f^{'}{g^{'}}$ are both bounded on the compact interval $[a,b]$. Hence,
$${\langle f,g\rangle}_W = \int_{a}^{b} f(t)g(t)+f'(x)g'(x) dt$$ is a finite quantity.
By breaking the integr and into real and imaginary parts, we can have that:
$$\int_{a}^{b} f(t)\overline{g(t)} = \overline{\int_{a}^{b} \overline{f(t)}g(t)dt}$$
It is also clear from properties of the integral that $(\alpha f,g)_W = \alpha (f,g)_W$ and $(f + g,h)_W = (f,h)_W + (g,h)_W$ for any $f,g,h \in W[a,b]$.\\
Then we need to prove that $(f,f)_W > 0$ for $f \neq 0$. Since $f \in W[a,b]$ is continuous on $[a,b]$, if $f$ differs from 0 at some $x_{*} \in [a,b]$, there must be some finite interval over which $f(x)\overline{f(x)} = |f(x)|^2 > 0$. Therefore,
$$\int_{a}^{b} f(x)\overline{f(x)} dt > 0$$
Therefore W[a,b] is a vector space and $(\cdot,\cdot)_W$ satifies all the properties of an inner product.\\

\question %Young 2.11 (p19)
Prove that in $W[0,1]$
$$
\langle f, \cosh\rangle = f(1)\sinh 1
$$
and deduce that
$$
\{ f\in W[0,1]\sst f(1)=0\}
$$
is a closed subspace of $W[0,1]$.\\

Proof: Given $W[0,1]: \mathbb{R} \rightarrow \mathbb{C}$ defined as the space of continuously differentiable functions with inner product $\langle f,g\rangle = \int_{0}^{1} f(t)g(t)+f'(x)g'(x) dt$
\begin{equation}
\begin{split}
\langle f, \cosh\rangle & = \int_{0}^{1} f(t) \cosh(t) + f^{'}(t) \cosh^{'}(t)dt\\
& = [F(t)\cosh(t)]_{0}^{1} - \int_{0}^{1} F(t)\cosh^{'}dt + [f(t)\cosh^{'}]_{0}^{1} - \int_{0}^{1}f(t)\cosh^{''}(t)dt\\
& = [f(t)\cosh^{'}(t)]_{0}^{1}\\
& = f(1)\sinh(1)\\
\end{split}
\end{equation}
To show that M is closed, as we have proved that $\langle f, \cosh\rangle = f(1)\sinh 1$, hence $$f(1) = 0$$
$$\Rightarrow {\langle f, \cosh\rangle}_W = 0$$
Therefore M is a closed subspace of $W[0,1]$

\question %Young 1.4 (p11)
Let $V$ be an inner product space and let $x,y\in V$. Prove Pythagoras' theorem:
$$
\langle x,y\rangle = 0 \ts\Ra\ts {\lVert x+y\rVert}^2 = {\lVert x\rVert}^2+{\lVert y\rVert}^2
$$
Proof: As $\langle x,y\rangle = 0$, we can know that $x$ and $y$ are orthogonal.Hence\\
\begin{equation}
\begin{split}
{\lVert x + y\rVert}^2 & = \langle x + y, x + y \rangle\\
& = \langle x,x \rangle + \langle v,v\rangle\\
& = {\lVert x \rVert}^2 + {\lVert y \rVert}^2\\
\end{split}
\end{equation}


\question %Young 2.2 (p19)
$\ell^1$ denotes the complex vector space of all absolutely summable sequences of complex numbers. That is 
all sequences $\{ x_n\}\subset\Complex$ such that 
$$
\sum_{n=1}^{\infty} \lvert x_n\rvert < \infty
$$
with componentwise addition and scalar multiplication. Show that
$$
\lVert x\rVert_1 = \sum_{n=1}^{\infty} \lvert x_n\rvert
$$
defines a norm on $\ell^1$.\\
Proof: $\ell^1$ denotes the space of all absolutely summable sequences $\big\{ x_n \big\} \subset \mathbb{C}$, that is: 
$$\ell^1 = \big\{ {x = (x_n)_{n \in \mathbb{N}} : \sum_{n=1}^\infty |x_k|<\infty}\big\}$$
This set is a vector space. In particular, it is closed under the operations of addition of sequences and multiplication of a sequence by a scalar. Further, a straightforward calculation shows that the function $d$ defined by 
$$d(x,y) = {||x-y||}_1 = \sum_{n=1}^\infty |x_n - y_n|, x,y \in \ell^1$$
is a metric on $\ell^1$, so $\ell^1$ is both a vector space and a metric space.\\
Therefore, there exists a sequence of real or complex scalars
$$x = (x_{n})_{n \in \mathbb{N}} = (x_1,x_2,...)$$
with the define of the $\ell^1$-norm of $x$ to be
$$||x||_1 = ||(x_n)_{n \in \mathbb{N}}||_1 = \sum_{n=1}^\infty |x_n|$$

\question %Young 2.6 (p19)
Show that the subspace of polynomial functions is not closed in $C[0,1]$ (continuous real functions on $[0,1]$)
with respect to either the supremum norm
$$
\lVert f\rVert_{\infty} = \sup_{x\in [0,1]} \lvert f(x)\rvert
$$
or the inner product norm
$$
\lVert f\rVert_2 = \langle f, f\rangle^{1/2} = \left(\int_{0}^{1} f(x)^2 dx\right)^{1/2}
$$
(\textit{hint}: find a limit point that is not a polynomial)\\

Proof: from
\begin{equation}
\begin{split}
\lVert f\rVert_{\infty} & = \sup_{x\in [0,1]} \lvert f(x)\rvert\\
\lVert f\rVert_2 &= \langle f, f\rangle^{1/2} = \left(\int_{0}^{1} f(x)^2 dx\right)^{1/2}
\end{split}
\end{equation}
Hence,
\begin{equation}
\begin{split}
\lVert f\rVert_2 \leq \lVert f\rVert_{\infty}.\left(\int_{0}^{1} dx \right)^{1/2}=\lVert f\rVert_{\infty} \tag{1}\\
\end{split}
\end{equation}
Suppose a non-polynomial function $f = e^x$. \\
Denote the partial sum of its Taylor series expansion as $Tn$. $(T_n)^{\infty}_{n=1}$ is a a sequence of polynomials, therefore,
$$
\lVert Pn-f\rVert_{\infty}\to 0 $$\\
$$ \Rightarrow
\lVert P_n-f\rVert_2 \leq \lVert P_n-f\rVert_{
\infty} \to 0 $$
Therefore the subspace of polynomial functions is not closed in C[0,1], neither the inner product norm.\\

\question %Young 2.7 (p19)
$c_0$ denotes the subspace of $\ell^{\infty}$ comprising all sequences $\{ x_n\}$ which converge to zero as $n\to\infty$.
Prove that $c_0$ is closed in $\ell^{\infty}$ (with respect to $\lVert\cdot\rVert_{\infty}$).\\

Proof: We need to prove that the limit of sequence in $c_0$ that converges in $l^\infty$ is actually in $c_0$. Considering a sequence of elements $((x_{n}^{m})_n)_m$ of $c_0$, denote $(x_n)_n$ as the limit of that sequence in $l^\infty$.\\
Let $\varepsilon > 0$, $\exists M \in \mathbb{N}$ s.t. $\forall m \geq M$, 
$$||(x_{n}^{m})_{n} - (x_n)_n||_{\infty} < \frac{\varepsilon}{2}$$
As we know that sequences $\big\{ x_n \big\}$ converge to zero as $n \rightarrow \infty$, then $\lim_{n \rightarrow \infty}x_{n}^{m} = 0$. Hence, $$|x_{n}^{m}| < \frac{\varepsilon}{2}$$
$$|x_n| \leq |x_n - x_{n}^{m}| + |x_{n}^{m}| < \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon$$
Therefore, $\lim_{n \rightarrow \infty}x_n = 0$, $c_0$ is closed in $l^\infty$

\question %Young Ex3.3 (p23)
Prove that $\ell^{\infty}$ with the supremum norm $\lVert\cdot\rVert_{\infty}$ is complete.\\

Proof: $l^\infty$ is said complete if every Cauchy sequence of points in $l^\infty$ has a limit that is also in $l^{\infty}$ or alternatively, if every Cauchy sequence in $l^\infty$ converges in $l^\infty$. Hence we have to show that a Cauchy sequence in $l^\infty$ converges.\\
Consider a Cauchy sequence $(x_n)$ in $l^\infty$. Each $x_n$ is itself a sequence, and denote it by $$x_n(0), x_n(1),...$$
and $x_n(k)$ means the $k$th term in the $n$th element of the sequence.\\
We nned to find an element $x$ in $l^\infty$ such that $x_n$ converges to $x$.
Let $\varepsilon > 0$, as $x_n$ is a Cauchy sequence, $\exists N \in \mathbb{N}, N > 0$ such that $$||x_n - x_m||_\infty < \varepsilon$$
for all $n, m > N$\\
Hence, $$|x_{n}^{k} - x_{m}^{k}| < \varepsilon$$
for all $n, m > N$
Therefore, every Cauchy sequence in $l^\infty$ converges. $l^\infty$ with the supremum norm $\lVert\cdot\rVert_{\infty}$ is complete.


\end{questions}
\end{document}
